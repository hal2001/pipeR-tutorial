```{r knitsetup, echo=FALSE, results='hide', warning=FALSE, message=FALSE, cache=FALSE}
opts_knit$set(base.dir='./', fig.path='', out.format='md')
opts_chunk$set(prompt=FALSE, comment='#', fig.align = 'center', results='markup')
```

# rvest

[rvest](https://github.com/hadley/rvest) is a new R package to make it easy to scrape information from web pages. In this example, we show a simple scraping task using pipeR's `Pipe()` together with side effects to indicate scraping process.

In this example, we scrape the description of [CRAN packages](http://cran.r-project.org/web/packages/available_packages_by_date.html) and list the most popular keywords.

First, we load the libaries we need.

```{r,message=FALSE}
library(rvest) # devtools::install_github("hadley/rvest")
library(rlist) # devtools::install_github("rlist","renkun-ken")
library(pipeR)
```

Then we build a pipeline to scrape the texts in the description column, split the texts into words, create a table in which the most popular keywords are listed. To monitor the process, we add some side effects using `message()` to indicate the working progress.

```{r}
url <- "http://cran.r-project.org/web/packages/available_packages_by_date.html"
Pipe(url)$
  .(~ message(Sys.time(),": downloading"))$
  html()$
  html_nodes(xpath = "//tr//td[3]")$
  .(~ message("number of packages: ", length(.)))$
  html_text(trim = TRUE)$
  .(~ message(Sys.time(),": text extracted"))$
  list.map(Pipe(.)$
      strsplit("[^a-zA-Z]")$
      unlist(use.names = FALSE)$
      tolower()$
      list.filter(nchar(.) > 3L)$
      value)$
    # put everything in a large character vector
  unlist()$
  # create a table of word count
  table()$
  # sort the table descending
  sort(decreasing = TRUE)$
  # take out the first 100 elements
  head(50)$
  .(~ message(Sys.time(),": task complete"))
```

As we have pointed out, the side effects use special syntax so it is easy to distinguish mainstream pipeline and side effect steps.
